{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_downloader.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/Kaggle/blob/master/Earthquake_Prediction/data_downloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GAkHtbPNPDP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Code to download the data"
      ]
    },
    {
      "metadata": {
        "id": "uPoSZuZ3el-R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xuoGSsaweozM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "token = {\"username\":\"dkatsios\",\"key\":\"684d38a2e65bba3b1fcaecf462caae75\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IxFypRf7ewNw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlopVEkFJ76e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c LANL-Earthquake-Prediction -p /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GBevEyQqMr9_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2zBArOfcKg6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip train.csv.zip && rm train.csv.zip\n",
        "!unzip test.zip -d test && rm test.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QXcFBqQOO8qB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Code after downloading the data"
      ]
    },
    {
      "metadata": {
        "id": "MMDN_0oBPLT6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from glob import glob\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Input, Conv1D, Dense, MaxPool1D, BatchNormalization, Dropout, ReLU\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rOA2ov5PPPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_csv_path = 'train.csv'\n",
        "test_folder = 'test/'\n",
        "model_path = 'model_0.h5'\n",
        "sub_csv_path = 'results_0.csv'\n",
        "\n",
        "total_rows = 629145481\n",
        "batch_size = 256\n",
        "steps_per_epoch = (total_rows // batch_size) - 2\n",
        "epochs = 1\n",
        "\n",
        "k_size = 5\n",
        "n_kernels = 4\n",
        "max_n_kernels = 2**11\n",
        "n_layers = 9\n",
        "chunk_size = 2**n_layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F4yhFGRIVmgO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the data loaders objects (generators)"
      ]
    },
    {
      "metadata": {
        "id": "VECoE1BnfdDh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CSVReader:\n",
        "  def __init__(self, csv_path, chunk_size, batch_size, only_last_t=True):\n",
        "    self.only_last_t = only_last_t\n",
        "    self.chunk_size = chunk_size\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "    self.datareader = pd.read_csv(csv_path, chunksize=chunk_size)\n",
        "    \n",
        "  def __iter__(self):\n",
        "    return self\n",
        "  \n",
        "  def get_chunk(self):\n",
        "    chunk = next(self.datareader).values\n",
        "    vs, ts = chunk[:, 0], chunk[:, 1]\n",
        "    return (vs, ts[-1]) if self.only_last_t else (vs, ts)\n",
        "  \n",
        "  def __next__(self):\n",
        "    vs = np.zeros((self.batch_size, self.chunk_size))\n",
        "    ts = np.zeros((self.batch_size, 1 if self.only_last_t else self.chunk_size))\n",
        "    for i in range(self.batch_size):\n",
        "      vs[i], ts[i] = self.get_chunk()\n",
        "    return np.expand_dims(vs, -1), np.expand_dims(ts, -1)\n",
        "  \n",
        "  \n",
        "class CSVTester:\n",
        "  def __init__(self, csv_path, chunk_size, batch_size):\n",
        "    self.chunk_size = chunk_size\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "    self.datareader = pd.read_csv(csv_path, chunksize=chunk_size)\n",
        "    \n",
        "  def __iter__(self):\n",
        "    return self\n",
        "  \n",
        "  def get_chunk(self):\n",
        "    chunk = next(self.datareader).values\n",
        "    return chunk\n",
        "  \n",
        "  def __next__(self):\n",
        "    batch = np.zeros((self.batch_size, self.chunk_size, 1))\n",
        "    for i in range(self.batch_size):\n",
        "      batch[i] = self.get_chunk()\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aC7tE98wVubN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the model"
      ]
    },
    {
      "metadata": {
        "id": "dmQJN2dkam4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model(chunk_size, n_kernels, max_n_kernels, k_size, n_layers):\n",
        "  \n",
        "  def my_block(x, drp):\n",
        "    x = Conv1D(min(max_n_kernels, n_kernels*2**i), k_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    if drp: x = Dropout(0.5)(x)\n",
        "    x = MaxPool1D()(x)\n",
        "    return x\n",
        "  \n",
        "  x = input = Input((chunk_size, 1))\n",
        "  \n",
        "  for i in range(1, n_layers+1):\n",
        "    x = my_block(x, i < n_layers)\n",
        "    \n",
        "  output = Dense(1)(x)\n",
        "  model = Model(input, output)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3fKjktkVxT_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the inference and results generation functions"
      ]
    },
    {
      "metadata": {
        "id": "Rwv5Knu-nz3H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_pred_for_csv(model, csv_path, chunk_size, batch_size):\n",
        "  csv_reader = CSVTester(csv_path, chunk_size, batch_size)\n",
        "  preds = []\n",
        "  try:\n",
        "    for batch in csv_reader:\n",
        "        pred = model.predict_on_batch(batch)\n",
        "        preds.extend(pred)\n",
        "  except ValueError:\n",
        "    pass\n",
        "  return np.mean(preds)\n",
        "\n",
        "\n",
        "def produce_sub_file(test_folder, sub_csv_path, model, chunk_size, batch_size):\n",
        "  test_csv_paths = glob(test_folder + '*')\n",
        "  with open(sub_csv_path, 'w') as f:\n",
        "    line = 'seg_id,time_to_failure'\n",
        "    f.write(line)\n",
        "    \n",
        "    for i, test_csv_path in enumerate(test_csv_paths, 1):\n",
        "      test_id = os.path.basename(test_csv_path).replace('.csv', '')\n",
        "      pred = get_pred_for_csv(model, test_csv_path, chunk_size, batch_size)\n",
        "      line = '\\n%s,%f' % (test_id, pred)\n",
        "      print('\\r%s (%d/%d)' % (line[2:], i, len(test_csv_paths)), end='')\n",
        "      f.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oX99Sgs0V6Gc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test the data loader and batch shapes"
      ]
    },
    {
      "metadata": {
        "id": "yk7vcnxJNEEd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "csv_reader = CSVReader(train_csv_path, chunk_size, batch_size)\n",
        "vs, ts = next(csv_reader)\n",
        "vs.shape, ts.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i-5verAxV_Bk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build and compile the model and the data generator (it is very simplistic approach so no validation generator is used...)"
      ]
    },
    {
      "metadata": {
        "id": "L6soHJ-ATTEt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "model = get_model(chunk_size, n_kernels, max_n_kernels, k_size, n_layers)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laV6tfnWWgtH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile('adam', 'mse', metrics=['acc'])\n",
        "csv_reader = CSVReader(train_csv_path, chunk_size, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uylw_x_8WNAR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ]
    },
    {
      "metadata": {
        "id": "OKSfnkCjdHIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(csv_reader, steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
        "model.save(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cn4HFwabWWSI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Produce and download the output file for submission"
      ]
    },
    {
      "metadata": {
        "id": "hu_IFd-CCE3-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "produce_sub_file(test_folder, sub_csv_path, model, chunk_size, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdnIovfhNNyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(sub_csv_path) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}